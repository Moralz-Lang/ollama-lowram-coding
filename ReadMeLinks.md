# Ollama Lowâ€‘RAM Coding Assistant

[![Repo Size](https://img.shields.io/github/repo-size/Moralz-Lang/ollama-lowram-coding)](https://github.com/Moralz-Lang/ollama-lowram-coding)
[![Issues](https://img.shields.io/github/issues/Moralz-Lang/ollama-lowram-coding)](https://github.com/Moralz-Lang/ollama-lowram-coding/issues)
[![Stars](https://img.shields.io/github/stars/Moralz-Lang/ollama-lowram-coding)](https://github.com/Moralz-Lang/ollama-lowram-coding/stargazers)

A **fully local, lowâ€‘RAM AI coding assistant setup** using Ollama + Qwenâ€¯2.5â€‘Coderâ€¯1.5B â€” designed to run on CPUâ€‘only systems with limited memory.

---

## ğŸ“Œ Table of Contents

1. [About This Project](#about-this-project)  
2. [Hardware & System Requirements](#hardware--system-requirements)  
3. [Setup & Installation](#setup--installation)  
   * [ZRAM Swap (Critical)](#zram-swap-critical)  
   * [Install Ollama](#install-ollama)  
   * [Model Selection Logic](#model-selection-logic)  
4. [Model Profiles](#model-profiles)  
5. [Neovim Integration](#neovim-integration)  
6. [Parameter Tuning Guide](#parameter-tuning-guide)  
7. [Monitoring & Hygiene](#monitoring--hygiene)  
8. [Further Reading & Research](#further-reading--research)  
9. [Pros & Cons](#pros--cons)  
10. [Better Hardware Recommendations](#better-hardware-recommendations)  
11. [Final Verification](#final-verification)  
12. [Contributing](#contributing)

---

## ğŸ“Œ About This Project

This repository shows how to build and run a fully local coding assistant using Ollama on machines with:

- CPUâ€‘only (no GPU)
- Limited RAM (~1.8â€¯GB usable)
- No AVX support
- Arch Linux + Neovim

The full technical explanation is available in:

â¡ï¸ **[Lowâ€‘Resource LLM Reasoning & Preference Optimization.md](./Lowâ€‘Resource%20LLM%20Reasoning%20%26%20Preference%20Optimization.md)**

---

## ğŸ“Œ Hardware & System Requirements

Validated configuration:

- **CPU:** Intel Celeron N3450 (no AVX / AVX2)  
- **RAM:** ~1.8â€¯GB usable  
- **Storage:** SSD / NVMe  
- **OS:** Arch Linux  
- **Editor:** Neovim  
- **AI Runtime:** Ollama  
- **Model:** Qwenâ€¯2.5â€‘Coderâ€¯1.5B

â¡ï¸ Detailed analysis in: **[HardwareVerification.md](./HardwareVerification.md)**

---

## ğŸ“Œ Setup & Installation

### ğŸ§  ZRAM Swap (Critical)

Lowâ€‘RAM systems require ZRAM to prevent crashes:

â¡ï¸ **[3. ZRAM Swap(Critcal).md](./3.%20ZRAM%20Swap%28Critcal%29.md)**

---

### ğŸ›  Install Ollama

Stepâ€‘byâ€‘step install of the Ollama runtime:

â¡ï¸ **[4. Installing Ollama.md](./4.%20Installing%20Ollama.md)**

Official docs: https://github.com/ollama/ollama :contentReference[oaicite:1]{index=1}

---

### ğŸ“Š Model Selection Logic

Why Qwenâ€¯2.5â€‘Coder was chosen and evaluation of alternatives:

â¡ï¸ **[5. Model Selection Logic.md](./5.%20Model%20Selection%20Logic.md)**

---

## ğŸ“Œ Model Profiles

Profiles define different behaviors without duplicating weights:

â¡ï¸ **[6. Model Profiles (Behavioral Control).md](./6.%20Model%20Profiles%20%28Behavioral%20Control%29.md)**

Profiles included:
- qwenâ€‘n3450
- qwenâ€‘codeonly
- qwenâ€‘explain
- qwenâ€‘optimal

---

## ğŸ“Œ Neovim Integration

How to connect Ollama to Neovim workflows:

â¡ï¸ **[7. Neovim Integration.md](./7.%20Neovim%20Integration.md)**

---

## ğŸ“Œ Parameter Tuning Guide

Optimizing temperature, top_p, repeat_penalty, and context length:

â¡ï¸ **[8. Parameter Tuning Guide.md](./8.%20Parameter%20Tuning%20Guide.md)**

---

## ğŸ“Œ Monitoring & Hygiene

Commands for monitoring memory, disk, and cleanup:

â¡ï¸ **[9. Monitoring Commands](./9.%20Monitoring%20Commands)**

---

## ğŸ“Œ Further Reading & Research

Inâ€‘depth research and preference optimization:

â¡ï¸ **[Lowâ€‘Resource LLM Reasoning & Preference Optimization.md](./Lowâ€‘Resource%20LLM%20Reasoning%20%26%20Preference%20Optimization.md)**

---

## ğŸ“Œ Pros & Cons

Honest tradeâ€‘offs of this approach:

â¡ï¸ **[10. Pros & Cons.md](./10.%20Pros%20%26%20Cons.md)**

---

## ğŸ“Œ Better Hardware Recommendations

How the project can scale with more RAM, CPU, or GPU:

â¡ï¸ **[11. Better Hardware Recommendations.md](./11.%20Better%20Hardware%20Recommendations.md)**

---

## ğŸ“Œ Final Verification

Summary of verification steps and outcomes:

â¡ï¸ **[12. Final Verification.md](./12.%20Final%20Verification.md)**

---

## ğŸ“Œ Contributing

Contributions are welcome!  
Open an issue or submit a pull request.

