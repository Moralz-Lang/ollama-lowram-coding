---
```Evaluated Models```

---

Model	Rejected Because
---
LLaMA 3 8B	>8 GB RAM

Qwen 7B	Too slow / OOM

CodeLLaMA 7B	AVX dependency

GPT-NeoX	Excessive memory

---
Selected Model
ollama pull qwen2.5-coder:1.5b

---
Model source:
https://github.com/QwenLM
---
```Why this works:```

~1.5 GB memory footprint

No AVX requirement

Strong coding capability
